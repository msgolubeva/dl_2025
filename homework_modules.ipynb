{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"3MeKai5Xj6eX","executionInfo":{"status":"ok","timestamp":1743373718568,"user_tz":-180,"elapsed":7,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"wwlFrG-Tj6eY"},"source":["**Module** is an abstract class which defines fundamental methods necessary for a training a neural network. You do not need to change anything here, just read the comments."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"W8BLmtZ3j6eZ","executionInfo":{"status":"ok","timestamp":1743373718592,"user_tz":-180,"elapsed":16,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class Module(object):\n","    \"\"\"\n","    Basically, you can think of a module as of a something (black box)\n","    which can process `input` data and produce `ouput` data.\n","    This is like applying a function which is called `forward`:\n","\n","        output = module.forward(input)\n","\n","    The module should be able to perform a backward pass: to differentiate the `forward` function.\n","    More, it should be able to differentiate it if is a part of chain (chain rule).\n","    The latter implies there is a gradient from previous step of a chain rule.\n","\n","        gradInput = module.backward(input, gradOutput)\n","    \"\"\"\n","    def __init__ (self):\n","        self.output = None\n","        self.gradInput = None\n","        self.training = True\n","\n","    def forward(self, input):\n","        \"\"\"\n","        Takes an input object, and computes the corresponding output of the module.\n","        \"\"\"\n","        return self.updateOutput(input)\n","\n","    def backward(self,input, gradOutput):\n","        \"\"\"\n","        Performs a backpropagation step through the module, with respect to the given input.\n","\n","        This includes\n","         - computing a gradient w.r.t. `input` (is needed for further backprop),\n","         - computing a gradient w.r.t. parameters (to update parameters while optimizing).\n","        \"\"\"\n","        self.updateGradInput(input, gradOutput)\n","        self.accGradParameters(input, gradOutput)\n","        return self.gradInput\n","\n","\n","    def updateOutput(self, input):\n","        \"\"\"\n","        Computes the output using the current parameter set of the class and input.\n","        This function returns the result which is stored in the `output` field.\n","\n","        Make sure to both store the data in `output` field and return it.\n","        \"\"\"\n","\n","        # The easiest case:\n","\n","        self.output = input\n","        return self.output\n","\n","        pass\n","\n","    def updateGradInput(self, input, gradOutput):\n","        \"\"\"\n","        Computing the gradient of the module with respect to its own input.\n","        This is returned in `gradInput`. Also, the `gradInput` state variable is updated accordingly.\n","\n","        The shape of `gradInput` is always the same as the shape of `input`.\n","\n","        Make sure to both store the gradients in `gradInput` field and return it.\n","        \"\"\"\n","\n","        # The easiest case:\n","\n","        self.gradInput = gradOutput\n","        return self.gradInput\n","\n","        pass\n","\n","    def accGradParameters(self, input, gradOutput):\n","        \"\"\"\n","        Computing the gradient of the module with respect to its own parameters.\n","        No need to override if module has no parameters (e.g. ReLU).\n","        \"\"\"\n","        pass\n","\n","    def zeroGradParameters(self):\n","        \"\"\"\n","        Zeroes `gradParams` variable if the module has params.\n","        \"\"\"\n","        pass\n","\n","    def getParameters(self):\n","        \"\"\"\n","        Returns a list with its parameters.\n","        If the module does not have parameters return empty list.\n","        \"\"\"\n","        return []\n","\n","    def getGradParameters(self):\n","        \"\"\"\n","        Returns a list with gradients with respect to its parameters.\n","        If the module does not have parameters return empty list.\n","        \"\"\"\n","        return []\n","\n","    def train(self):\n","        \"\"\"\n","        Sets training mode for the module.\n","        Training and testing behaviour differs for Dropout, BatchNorm.\n","        \"\"\"\n","        self.training = True\n","\n","    def evaluate(self):\n","        \"\"\"\n","        Sets evaluation mode for the module.\n","        Training and testing behaviour differs for Dropout, BatchNorm.\n","        \"\"\"\n","        self.training = False\n","\n","    def __repr__(self):\n","        \"\"\"\n","        Pretty printing. Should be overrided in every module if you want\n","        to have readable description.\n","        \"\"\"\n","        return \"Module\""]},{"cell_type":"markdown","metadata":{"id":"mKRkIjT8j6eZ"},"source":["# Sequential container"]},{"cell_type":"markdown","metadata":{"id":"Cb98PPpJj6ea"},"source":["**Define** a forward and backward pass procedures."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"7y2lav4dj6ea","executionInfo":{"status":"ok","timestamp":1743373718645,"user_tz":-180,"elapsed":55,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class Sequential(Module):\n","    \"\"\"\n","         This class implements a container, which processes `input` data sequentially.\n","\n","         `input` is processed by each module (layer) in self.modules consecutively.\n","         The resulting array is called `output`.\n","    \"\"\"\n","\n","    def __init__ (self):\n","        super(Sequential, self).__init__()\n","        self.modules = []\n","        self.layer_inputs = []\n","\n","    def add(self, module):\n","        \"\"\"\n","        Adds a module to the container.\n","        \"\"\"\n","        self.modules.append(module)\n","\n","    def updateOutput(self, input):\n","        \"\"\"\n","        Basic workflow of FORWARD PASS:\n","\n","            y_0    = module[0].forward(input)\n","            y_1    = module[1].forward(y_0)\n","            ...\n","            output = module[n-1].forward(y_{n-2})\n","\n","\n","        Just write a little loop.\n","        \"\"\"\n","\n","        # Your code goes here. ################################################\n","        self.output = input\n","        self.layer_inputs = [input]  # Сохраняем входы для каждого слоя\n","        for module in self.modules:\n","            self.output = module.forward(self.output)\n","            self.layer_inputs.append(self.output)\n","        return self.output\n","\n","    def backward(self, input, gradOutput):\n","        \"\"\"\n","        Workflow of BACKWARD PASS:\n","\n","            g_{n-1} = module[n-1].backward(y_{n-2}, gradOutput)\n","            g_{n-2} = module[n-2].backward(y_{n-3}, g_{n-1})\n","            ...\n","            g_1 = module[1].backward(y_0, g_2)\n","            gradInput = module[0].backward(input, g_1)\n","\n","\n","        !!!\n","\n","        To ech module you need to provide the input, module saw while forward pass,\n","        it is used while computing gradients.\n","        Make sure that the input for `i-th` layer the output of `module[i]` (just the same input as in forward pass)\n","        and NOT `input` to this Sequential module.\n","\n","        !!!\n","\n","        \"\"\"\n","        # Your code goes here. ################################################\n","        self.gradInput = gradOutput\n","        # Обратный проход через слои в обратном порядке\n","        for i, module in enumerate(reversed(self.modules)):\n","            # Получаем вход, который был использован в прямом проходе для текущего модуля\n","            module_input = self.layer_inputs[-(i + 2)]  # -2, так как layer_inputs содержит входы до и после каждого слоя\n","            current_gradOutput = self.gradInput\n","            self.gradInput = module.backward(module_input, current_gradOutput)\n","            module.accGradParameters(module_input, current_gradOutput)\n","        return self.gradInput\n","\n","\n","    def zeroGradParameters(self):\n","        for module in self.modules:\n","            module.zeroGradParameters()\n","\n","    def getParameters(self):\n","        \"\"\"\n","        Should gather all parameters in a list.\n","        \"\"\"\n","        return [x.getParameters() for x in self.modules]\n","\n","    def getGradParameters(self):\n","        \"\"\"\n","        Should gather all gradients w.r.t parameters in a list.\n","        \"\"\"\n","        return [x.getGradParameters() for x in self.modules]\n","\n","    def __repr__(self):\n","        string = \"\".join([str(x) + '\\n' for x in self.modules])\n","        return string\n","\n","    def __getitem__(self,x):\n","        return self.modules.__getitem__(x)\n","\n","    def train(self):\n","        \"\"\"\n","        Propagates training parameter through all modules\n","        \"\"\"\n","        self.training = True\n","        for module in self.modules:\n","            module.train()\n","\n","    def evaluate(self):\n","        \"\"\"\n","        Propagates training parameter through all modules\n","        \"\"\"\n","        self.training = False\n","        for module in self.modules:\n","            module.evaluate()"]},{"cell_type":"code","source":["# import torch\n","# def test_Sequential_SimpleGradCheck():\n","#     np.random.seed(42)\n","#     torch.manual_seed(42)\n","\n","#     # Создаем простую модель: только ChannelwiseScaling\n","#     n_in = 3\n","#     custom_model = Sequential()\n","#     scaling_layer = ChannelwiseScaling(n_in)\n","#     custom_model.add(scaling_layer)\n","\n","#     # Инициализируем параметры как в PyTorch\n","#     torch_layer = torch.nn.Linear(n_in, n_in, bias=True)\n","#     scaling_layer.gamma = torch_layer.weight.data.numpy().copy()\n","#     scaling_layer.beta = torch_layer.bias.data.numpy().copy()\n","\n","#     # Тестовые данные\n","#     input_data = np.array([[1.0, 2.0, 3.0]], dtype=np.float32)\n","#     grad_output = np.array([[0.1, 0.2, 0.3]], dtype=np.float32)\n","\n","#     # Forward pass\n","#     custom_output = custom_model.updateOutput(input_data)\n","\n","#     # Backward pass\n","#     custom_model.zeroGradParameters()\n","#     custom_grad = custom_model.backward(input_data, grad_output)\n","\n","#     # Получаем градиенты параметров\n","#     weight_grad, bias_grad = custom_model.getGradParameters()\n","\n","#     # PyTorch расчет\n","#     torch_input = torch.tensor(input_data, requires_grad=True)\n","#     torch_output = torch_layer(torch_input)\n","#     torch_output.backward(torch.tensor(grad_output))\n","\n","#     # Проверка градиентов\n","#     assert np.allclose(torch_layer.weight.grad.numpy(), weight_grad, atol=1e-6), \\\n","#         f\"Ошибка в градиенте gamma: {torch_layer.weight.grad.numpy()} vs {weight_grad}\"\n","\n","#     assert np.allclose(torch_layer.bias.grad.numpy(), bias_grad, atol=1e-6), \\\n","#         f\"Ошибка в градиенте beta: {torch_layer.bias.grad.numpy()} vs {bias_grad}\"\n","\n","#     print(\"Тест пройден!\")\n","\n","# # Запуск теста\n","# test_Sequential_SimpleGradCheck()"],"metadata":{"id":"muto829nnAo2","executionInfo":{"status":"ok","timestamp":1743373718703,"user_tz":-180,"elapsed":61,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zfXdYfO4j6ea"},"source":["# Layers"]},{"cell_type":"markdown","metadata":{"id":"ZuwvBkuNj6ea"},"source":["## 1 (0.2). Linear transform layer\n","Also known as dense layer, fully-connected layer, FC-layer, InnerProductLayer (in caffe), affine transform\n","- input:   **`batch_size x n_feats1`**\n","- output: **`batch_size x n_feats2`**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"D0uoyqkpj6ea","executionInfo":{"status":"ok","timestamp":1743373718705,"user_tz":-180,"elapsed":41,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class Linear(Module):\n","    \"\"\"\n","    A module which applies a linear transformation\n","    A common name is fully-connected layer, InnerProductLayer in caffe.\n","\n","    The module should work with 2D input of shape (n_samples, n_feature).\n","    \"\"\"\n","    def __init__(self, n_in, n_out):\n","        super(Linear, self).__init__()\n","\n","        # This is a nice initialization\n","        stdv = 1./np.sqrt(n_in)\n","        self.W = np.random.uniform(-stdv, stdv, size = (n_out, n_in))\n","        self.b = np.random.uniform(-stdv, stdv, size = n_out)\n","\n","        self.gradW = np.zeros_like(self.W)\n","        self.gradb = np.zeros_like(self.b)\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        self.output = input @ self.W.T + self.b\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        self.gradInput = gradOutput @ self.W\n","        return self.gradInput\n","\n","    def accGradParameters(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        self.gradW += gradOutput.T @ input\n","        self.gradb += gradOutput.sum(axis=0)\n","        pass\n","\n","    def zeroGradParameters(self):\n","        self.gradW.fill(0)\n","        self.gradb.fill(0)\n","\n","    def getParameters(self):\n","        return [self.W, self.b]\n","\n","    def getGradParameters(self):\n","        return [self.gradW, self.gradb]\n","\n","    def __repr__(self):\n","        s = self.W.shape\n","        q = 'Linear %d -> %d' %(s[1],s[0])\n","        return q"]},{"cell_type":"markdown","metadata":{"id":"tNOnHXZJj6eb"},"source":["## 2. (0.2) SoftMax\n","- input:   **`batch_size x n_feats`**\n","- output: **`batch_size x n_feats`**\n","\n","$\\text{softmax}(x)_i = \\frac{\\exp x_i} {\\sum_j \\exp x_j}$\n","\n","Recall that $\\text{softmax}(x) == \\text{softmax}(x - \\text{const})$. It makes possible to avoid computing exp() from large argument."]},{"cell_type":"code","execution_count":8,"metadata":{"collapsed":true,"id":"VIValI0hj6eb","executionInfo":{"status":"ok","timestamp":1743373718708,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class SoftMax(Module):\n","    def __init__(self):\n","         super(SoftMax, self).__init__()\n","\n","    def updateOutput(self, input):\n","        # start with normalization for numerical stability\n","        self.output = np.subtract(input, input.max(axis=1, keepdims=True))\n","\n","        # Your code goes here. ################################################\n","        input_shifted = input - input.max(axis=1, keepdims=True)\n","        exp = np.exp(input_shifted)\n","        self.output = exp / exp.sum(axis=1, keepdims=True)\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        self.gradInput = np.zeros_like(input, dtype=np.float64)\n","        batch_size = input.shape[0]\n","\n","        for i in range(batch_size):\n","          s = self.output[i].reshape(-1, 1)\n","          jacobian = np.diagflat(s) - np.outer(s, s)\n","          self.gradInput[i] = (gradOutput[i] @ jacobian).reshape(-1)\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"SoftMax\""]},{"cell_type":"markdown","metadata":{"id":"Cy3DJjynj6eb"},"source":["## 3. (0.2) LogSoftMax\n","- input:   **`batch_size x n_feats`**\n","- output: **`batch_size x n_feats`**\n","\n","$\\text{logsoftmax}(x)_i = \\log\\text{softmax}(x)_i = x_i - \\log {\\sum_j \\exp x_j}$\n","\n","The main goal of this layer is to be used in computation of log-likelihood loss."]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":true,"id":"Xo7DRdAJj6eb","executionInfo":{"status":"ok","timestamp":1743373718712,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class LogSoftMax(Module):\n","    def __init__(self):\n","         super(LogSoftMax, self).__init__()\n","\n","    def updateOutput(self, input):\n","        # start with normalization for numerical stability\n","        self.output = np.subtract(input, input.max(axis=1, keepdims=True))\n","\n","        # Your code goes here. ################################################\n","        input_shifted = input - input.max(axis=1, keepdims=True)\n","        log_sum = np.log(np.exp(input_shifted).sum(axis=1, keepdims=True))\n","        self.output = input_shifted - log_sum\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        softmax = np.exp(self.output)\n","        self.gradInput = gradOutput - softmax * gradOutput.sum(axis=1, keepdims=True)\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"LogSoftMax\""]},{"cell_type":"markdown","metadata":{"id":"QP5QdmmPj6eb"},"source":["## 4. (0.3) Batch normalization\n","One of the most significant recent ideas that impacted NNs a lot is [**Batch normalization**](http://arxiv.org/abs/1502.03167). The idea is simple, yet effective: the features should be whitened ($mean = 0$, $std = 1$) all the way through NN. This improves the convergence for deep models letting it train them for days but not weeks. **You are** to implement the first part of the layer: features normalization. The second part (`ChannelwiseScaling` layer) is implemented below.\n","\n","- input:   **`batch_size x n_feats`**\n","- output: **`batch_size x n_feats`**\n","\n","The layer should work as follows. While training (`self.training == True`) it transforms input as $$y = \\frac{x - \\mu}  {\\sqrt{\\sigma + \\epsilon}}$$\n","where $\\mu$ and $\\sigma$ - mean and variance of feature values in **batch** and $\\epsilon$ is just a small number for numericall stability. Also during training, layer should maintain exponential moving average values for mean and variance:\n","```\n","    self.moving_mean = self.moving_mean * alpha + batch_mean * (1 - alpha)\n","    self.moving_variance = self.moving_variance * alpha + batch_variance * (1 - alpha)\n","```\n","During testing (`self.training == False`) the layer normalizes input using moving_mean and moving_variance.\n","\n","Note that decomposition of batch normalization on normalization itself and channelwise scaling here is just a common **implementation** choice. In general \"batch normalization\" always assumes normalization + scaling."]},{"cell_type":"code","execution_count":10,"metadata":{"collapsed":true,"id":"fGTTDqVgj6eb","executionInfo":{"status":"ok","timestamp":1743373718728,"user_tz":-180,"elapsed":13,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class BatchNormalization(Module):\n","    EPS = 1e-3\n","    def __init__(self, alpha = 0.):\n","        super(BatchNormalization, self).__init__()\n","        self.alpha = alpha\n","        self.moving_mean = None\n","        self.moving_variance = None\n","        self.batch_mean = None\n","        self.batch_var = None\n","        self.x_centered = None\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        # use self.EPS please\n","        if self.training:\n","            self.batch_mean = input.mean(axis=0)\n","            self.batch_var = input.var(axis=0, ddof=0) + self.EPS\n","            self.x_centered = input - self.batch_mean\n","            self.output = self.x_centered / np.sqrt(self.batch_var)\n","            # Обновление скользящих средних\n","            if self.moving_mean is None:\n","                self.moving_mean = self.batch_mean.copy()\n","                self.moving_variance = self.batch_var.copy()\n","            else:\n","                self.moving_mean = self.alpha * self.moving_mean + (1 - self.alpha) * self.batch_mean\n","                self.moving_variance = self.alpha * (self.moving_variance + self.EPS) + (1 - self.alpha) * self.batch_var\n","        else:\n","            self.output = (input - self.moving_mean) / np.sqrt(self.moving_variance + self.EPS)\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        if not self.training:\n","            # В режиме инференса градиент простой\n","            self.gradInput = gradOutput / np.sqrt(self.moving_variance + self.EPS)\n","            return self.gradInput\n","\n","        # Размер батча и количество признаков\n","        N = input.shape[0]\n","\n","        # Градиенты через цепное правило\n","        std_inv = 1.0 / np.sqrt(self.batch_var)\n","\n","        # 1. Градиент по нормализованным данным\n","        dldx_hat = gradOutput * std_inv\n","\n","        # 2. Градиент по дисперсии\n","        dldvar = np.sum(gradOutput * self.x_centered * (-0.5) * (self.batch_var ** (-1.5)), axis=0)\n","\n","        # 3. Градиент по среднему\n","        dldmean = np.sum(gradOutput * (-std_inv), axis=0) + dldvar * (-2.0 / N) * np.sum(self.x_centered, axis=0)\n","\n","        # Итоговый градиент\n","        self.gradInput = (dldx_hat +\n","                         (2.0 / N) * dldvar * self.x_centered +\n","                         (1.0 / N) * dldmean)\n","\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"BatchNormalization\""]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"id":"8XUS3Lt-j6eb","executionInfo":{"status":"ok","timestamp":1743373718745,"user_tz":-180,"elapsed":15,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class ChannelwiseScaling(Module):\n","    \"\"\"\n","       Implements linear transform of input y = \\gamma * x + \\beta\n","       where \\gamma, \\beta - learnable vectors of length x.shape[-1]\n","    \"\"\"\n","    def __init__(self, n_out):\n","        super(ChannelwiseScaling, self).__init__()\n","\n","        stdv = 1./np.sqrt(n_out)\n","        self.gamma = np.random.uniform(-stdv, stdv, size=n_out).astype(np.float32)\n","        self.beta = np.random.uniform(-stdv, stdv, size=n_out).astype(np.float32)\n","\n","        self.gradGamma = np.zeros_like(self.gamma)\n","        self.gradBeta = np.zeros_like(self.beta)\n","\n","    def updateOutput(self, input):\n","        self.output = input * self.gamma + self.beta\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        self.gradInput = gradOutput * self.gamma\n","        return self.gradInput\n","\n","    def accGradParameters(self, input, gradOutput):\n","        self.gradBeta = np.sum(gradOutput, axis=0)\n","        self.gradGamma = np.sum(gradOutput*input, axis=0)\n","\n","    def zeroGradParameters(self):\n","        self.gradGamma.fill(0)\n","        self.gradBeta.fill(0)\n","\n","    def getParameters(self):\n","        return [self.gamma, self.beta]\n","\n","    def getGradParameters(self):\n","        return [self.gradGamma, self.gradBeta]\n","\n","    def __repr__(self):\n","        return \"ChannelwiseScaling\""]},{"cell_type":"markdown","metadata":{"id":"vA5zjM3jj6eb"},"source":["Practical notes. If BatchNormalization is placed after a linear transformation layer (including dense layer, convolutions, channelwise scaling) that implements function like `y = weight * x + bias`, than bias adding become useless and could be omitted since its effect will be discarded while batch mean subtraction. If BatchNormalization (followed by `ChannelwiseScaling`) is placed before a layer that propagates scale (including ReLU, LeakyReLU) followed by any linear transformation layer than parameter `gamma` in `ChannelwiseScaling` could be freezed since it could be absorbed into the linear transformation layer."]},{"cell_type":"markdown","metadata":{"id":"Gackeo1cj6eb"},"source":["## 5. (0.3) Dropout\n","Implement [**dropout**](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf). The idea and implementation is really simple: just multimply the input by $Bernoulli(p)$ mask. Here $p$ is probability of an element to be zeroed.\n","\n","This has proven to be an effective technique for regularization and preventing the co-adaptation of neurons.\n","\n","While training (`self.training == True`) it should sample a mask on each iteration (for every batch), zero out elements and multiply elements by $1 / (1 - p)$. The latter is needed for keeping mean values of features close to mean values which will be in test mode. When testing this module should implement identity transform i.e. `self.output = input`.\n","\n","- input:   **`batch_size x n_feats`**\n","- output: **`batch_size x n_feats`**"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"NmLQV3jXj6eb","executionInfo":{"status":"ok","timestamp":1743373718747,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class Dropout(Module):\n","    def __init__(self, p=0.5):\n","        super(Dropout, self).__init__()\n","\n","        self.p = p\n","        self.mask = None\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        if self.training:\n","            self.mask = (np.random.rand(*input.shape) > self.p) / (1 - self.p)\n","            self.output = input * self.mask\n","        else:\n","            self.output = input\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        self.gradInput = gradOutput * self.mask if self.training else gradOutput\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"Dropout\""]},{"cell_type":"markdown","source":["## 6. (2.0) Conv2d\n","Implement [**Conv2d**](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html). Use only this list of parameters: (in_channels, out_channels, kernel_size, stride, padding, bias, padding_mode) and fix dilation=1 and groups=1."],"metadata":{"id":"-WHGIqJFlhz2"}},{"cell_type":"code","source":["class Conv2d(Module):\n","    def __init__(self, in_channels, out_channels, kernel_size,\n","                 stride=1, padding=0, bias=True, padding_mode='zeros'):\n","        super(Conv2d, self).__init__()\n","\n","        self.in_channels = in_channels\n","        self.out_channels = out_channels\n","        if isinstance(kernel_size, int):\n","            self.kernel_size = (kernel_size, kernel_size)\n","        else:\n","            self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.bias = bias\n","        self.padding_mode = padding_mode\n","\n","        kH, kW = self.kernel_size\n","        self.weight = np.random.randn(out_channels, in_channels, kH, kW).astype(np.float32)\n","        if self.bias:\n","            self.bias = np.random.randn(out_channels).astype(np.float32)\n","        else:\n","            self.bias = None\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","\n","        pad = self.padding\n","        padded_input = np.pad(input,\n","                              pad_width=((0,0), (0,0), (pad, pad), (pad, pad)),\n","                              mode='constant')\n","\n","        N, C, H_pad, W_pad = padded_input.shape\n","        kH, kW = self.kernel_size\n","        stride = self.stride\n","\n","        H_out = (H_pad - kH) // stride + 1\n","        W_out = (W_pad - kW) // stride + 1\n","\n","        shape = (N, C, H_out, W_out, kH, kW)\n","        strides = (padded_input.strides[0],\n","                   padded_input.strides[1],\n","                   stride * padded_input.strides[2],\n","                   stride * padded_input.strides[3],\n","                   padded_input.strides[2],\n","                   padded_input.strides[3])\n","        strided = np.lib.stride_tricks.as_strided(padded_input,\n","                                                  shape=shape,\n","                                                  strides=strides,\n","                                                  writeable=False)\n","\n","        cols = strided.transpose(0, 2, 3, 1, 4, 5).reshape(-1, C * kH * kW).T\n","\n","        weight_matrix = self.weight.reshape(self.out_channels, -1)\n","        output_flat = weight_matrix @ cols\n","\n","        output = output_flat.reshape(self.out_channels, N, H_out, W_out).transpose(1, 0, 2, 3)\n","\n","        if self.bias is not None:\n","            output += self.bias.reshape(1, -1, 1, 1)\n","\n","        self.output = output\n","\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        N, C, H, W = input.shape\n","        pad = self.padding\n","        kH, kW = self.kernel_size\n","        stride = self.stride\n","\n","        H_pad = H + 2 * pad\n","        W_pad = W + 2 * pad\n","        H_out = (H_pad - kH) // stride + 1\n","        W_out = (W_pad - kW) // stride + 1\n","\n","        gradOutput_reshaped = gradOutput.transpose(1, 0, 2, 3).reshape(self.out_channels, -1)\n","\n","        W_flat = self.weight.reshape(self.out_channels, -1)\n","        dX_col = W_flat.T @ gradOutput_reshaped\n","\n","        padded_grad = np.zeros((N, C, H_pad, W_pad), dtype=input.dtype)\n","\n","        i_indices = np.arange(N * H_out * W_out)\n","        n = i_indices // (H_out * W_out)\n","        rest = i_indices % (H_out * W_out)\n","        h_out = rest // W_out\n","        w_out = rest % W_out\n","\n","        h_start = h_out * stride\n","        w_start = w_out * stride\n","\n","        rows = np.arange(C * kH * kW)\n","        c, kh, kw = np.unravel_index(rows, (C, kH, kW))\n","\n","        n_full = np.repeat(n, C*kH*kW)\n","        c_full = np.tile(c, N * H_out * W_out)\n","        h_full = np.repeat(h_start, C*kH*kW) + np.tile(kh, N * H_out * W_out)\n","        w_full = np.repeat(w_start, C*kH*kW) + np.tile(kw, N * H_out * W_out)\n","\n","        h_full = np.clip(h_full, 0, H_pad - 1)\n","        w_full = np.clip(w_full, 0, W_pad - 1)\n","\n","        dX_flat = dX_col.T.ravel()\n","        np.add.at(padded_grad, (n_full, c_full, h_full, w_full), dX_flat)\n","\n","        self.gradInput = padded_grad[:, :, pad:H_pad - pad, pad:W_pad - pad]\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"Conv2d\""],"metadata":{"id":"c1RjNoEXlOHP","executionInfo":{"status":"ok","timestamp":1743373718768,"user_tz":-180,"elapsed":8,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## 7. (0.5) Implement [**MaxPool2d**](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html) and [**AvgPool2d**](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html). Use only parameters like kernel_size, stride, padding (negative infinity for maxpool and zero for avgpool) and other parameters fixed as in framework."],"metadata":{"id":"updUVZE9qixP"}},{"cell_type":"code","source":["class MaxPool2d(Module):\n","    def __init__(self, kernel_size, stride, padding):\n","        super(MaxPool2d, self).__init__()\n","\n","        self.kernel_size = kernel_size if isinstance(kernel_size, tuple) else (kernel_size, kernel_size)\n","        self.stride = stride if isinstance(stride, tuple) else (stride, stride)\n","        self.padding = padding if isinstance(padding, tuple) else (padding, padding)\n","\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        padH, padW = self.padding\n","        kH, kW = self.kernel_size\n","        sH, sW = self.stride\n","\n","        # Применяем padding к входу\n","        padded_input = np.pad(input, ((0,0), (0,0), (padH, padH), (padW, padW)), mode='constant')\n","        N, C, H_padded, W_padded = padded_input.shape\n","\n","        # Вычисляем размеры выхода\n","        out_h = (H_padded - kH) // sH + 1\n","        out_w = (W_padded - kW) // sW + 1\n","\n","        # Создаем окна с использованием as_strided\n","        strides = padded_input.strides\n","        new_strides = (strides[0], strides[1], sH * strides[2], sW * strides[3], strides[2], strides[3])\n","        windows = np.lib.stride_tricks.as_strided(padded_input, shape=(N, C, out_h, out_w, kH, kW), strides=new_strides)\n","\n","        # Находим максимумы и их индексы\n","        windows_flat = windows.reshape(N, C, out_h, out_w, -1)\n","        self.output = np.max(windows_flat, axis=-1)\n","        max_indices = np.argmax(windows_flat, axis=-1)\n","\n","        # Сохраняем индексы для обратного прохода\n","        self.h_idx = max_indices // kW\n","        self.w_idx = max_indices % kW\n","        self.input_shape = input.shape\n","\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        if not hasattr(self, 'h_idx') or not hasattr(self, 'w_idx'):\n","            raise RuntimeError(\"Сначала выполните forward pass\")\n","\n","        padH, padW = self.padding\n","        kH, kW = self.kernel_size\n","        sH, sW = self.stride\n","        N, C, out_h, out_w = gradOutput.shape\n","        H_padded = self.input_shape[2] + 2 * padH\n","        W_padded = self.input_shape[3] + 2 * padW\n","\n","        # Создаем массив для накопления градиентов с учетом padding\n","        gradInput_padded = np.zeros((N, C, H_padded, W_padded), dtype=input.dtype)\n","\n","        # Вычисляем начальные позиции окон\n","        i = np.arange(out_h) * sH\n","        j = np.arange(out_w) * sW\n","\n","        # Формируем индексы для всех элементов\n","        h_start = i.reshape(1, 1, out_h, 1)\n","        w_start = j.reshape(1, 1, 1, out_w)\n","\n","        # Вычисляем позиции максимумов в padded_input\n","        h_padded = h_start + self.h_idx\n","        w_padded = w_start + self.w_idx\n","\n","        # Преобразуем все индексы в плоские массивы\n","        n_indices = np.broadcast_to(np.arange(N)[:, None, None, None], (N, C, out_h, out_w)).flatten()\n","        c_indices = np.broadcast_to(np.arange(C)[None, :, None, None], (N, C, out_h, out_w)).flatten()\n","        h_flat = h_padded.flatten()\n","        w_flat = w_padded.flatten()\n","        grad_flat = gradOutput.flatten()\n","\n","        # Накопление градиентов с помощью np.add.at\n","        np.add.at(gradInput_padded, (n_indices, c_indices, h_flat, w_flat), grad_flat)\n","\n","        # Удаляем padding\n","        self.gradInput = gradInput_padded[:, :, padH:H_padded-padH, padW:W_padded-padW]\n","\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"MaxPool2d\"\n","\n","class AvgPool2d(Module):\n","    def __init__(self, kernel_size, stride, padding):\n","        super(AvgPool2d, self).__init__()\n","\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        kh, kw = (self.kernel_size, self.kernel_size) if isinstance(self.kernel_size, int) else self.kernel_size\n","        sh, sw = (self.stride, self.stride) if isinstance(self.stride, int) else self.stride\n","        ph, pw = (self.padding, self.padding) if isinstance(self.padding, int) else self.padding\n","\n","        # Применение паддинга\n","        padded_input = np.pad(input, ((0, 0), (0, 0), (ph, ph), (pw, pw)), mode='constant')\n","\n","        N, C, H_pad, W_pad = padded_input.shape\n","        out_h = (H_pad - kh) // sh + 1\n","        out_w = (W_pad - kw) // sw + 1\n","\n","        # Создание окон через as_strided\n","        new_shape = (N, C, out_h, out_w, kh, kw)\n","        batch_stride, channel_stride, h_stride, w_stride = padded_input.strides\n","        new_strides = (\n","            batch_stride,\n","            channel_stride,\n","            sh * h_stride,\n","            sw * w_stride,\n","            h_stride,\n","            w_stride\n","        )\n","        windows = np.lib.stride_tricks.as_strided(padded_input, new_shape, new_strides)\n","\n","        # Усреднение по окну\n","        self.output = np.mean(windows, axis=(4, 5))\n","        return  self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        kh, kw = (self.kernel_size, self.kernel_size) if isinstance(self.kernel_size, int) else self.kernel_size\n","        sh, sw = (self.stride, self.stride) if isinstance(self.stride, int) else self.stride\n","        ph, pw = (self.padding, self.padding) if isinstance(self.padding, int) else self.padding\n","\n","        N, C, H_in, W_in = input.shape\n","        H_pad = H_in + 2 * ph\n","        W_pad = W_in + 2 * pw\n","\n","        # Инициализация grad_padded\n","        grad_padded = np.zeros((N, C, H_pad, W_pad), dtype=input.dtype)\n","        scale = 1.0 / (kh * kw)\n","\n","        # Ручное распределение градиентов по окнам\n","        for n in range(N):\n","            for c in range(C):\n","                for i in range(gradOutput.shape[2]):\n","                    for j in range(gradOutput.shape[3]):\n","                        h_start = i * sh\n","                        h_end = h_start + kh\n","                        w_start = j * sw\n","                        w_end = w_start + kw\n","                        grad_padded[n, c, h_start:h_end, w_start:w_end] += gradOutput[n, c, i, j] * scale\n","\n","        # Обрезка паддинга\n","        self.gradInput = grad_padded[:, :, ph:ph+H_in, pw:pw+W_in]\n","\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"AvgPool2d\""],"metadata":{"id":"Qys58EzkqhLj","executionInfo":{"status":"ok","timestamp":1743373718803,"user_tz":-180,"elapsed":38,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## 8. (0.3) Implement **GlobalMaxPool2d** and **GlobalAvgPool2d**. They do not have testing and parameters are up to you but they must aggregate information within channels. Write test functions for these layers on your own."],"metadata":{"id":"KTN5R3CwrukV"}},{"cell_type":"markdown","source":["#9. (0.2) Implement [**Flatten**](https://pytorch.org/docs/stable/generated/torch.flatten.html)"],"metadata":{"id":"cYeBQDBhtViy"}},{"cell_type":"code","source":["class Flatten(Module):\n","    def __init__(self, start_dim=0, end_dim=-1):\n","        super(Flatten, self).__init__()\n","\n","        self.start_dim = start_dim\n","        self.end_dim = end_dim\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        input_size = input.shape\n","        ndim = input.ndim\n","\n","        # Преобразование отрицательных индексов\n","        end_dim = self.end_dim if self.end_dim >= 0 else ndim + self.end_dim\n","        start_dim = self.start_dim if self.start_dim >= 0 else ndim + self.start_dim\n","\n","        # Проверка валидности индексов\n","        if start_dim < 0 or start_dim >= ndim:\n","            raise ValueError(f\"start_dim {self.start_dim} is out of range for input with {ndim} dimensions\")\n","        if end_dim < 0 or end_dim >= ndim:\n","            raise ValueError(f\"end_dim {self.end_dim} is out of range for input with {ndim} dimensions\")\n","        if start_dim > end_dim:\n","            raise ValueError(f\"start_dim ({start_dim}) must be <= end_dim ({end_dim})\")\n","\n","        # Вычисление новой формы\n","        new_shape = list(input_size[:start_dim])\n","        flattened_size = 1\n","        for i in range(start_dim, end_dim + 1):\n","            flattened_size *= input_size[i]\n","        new_shape.append(flattened_size)\n","        new_shape += list(input_size[end_dim + 1:])\n","\n","        self.output = input.reshape(new_shape)\n","        self.input_shape = input_size  # Сохраняем форму для обратного прохода\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        self.gradInput = gradOutput.reshape(self.input_shape)\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"Flatten\""],"metadata":{"id":"SimPEMOFqhTQ","executionInfo":{"status":"ok","timestamp":1743373718838,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o36vPHSSj6eb"},"source":["# Activation functions"]},{"cell_type":"markdown","metadata":{"id":"l_pryRQIj6ec"},"source":["Here's the complete example for the **Rectified Linear Unit** non-linearity (aka **ReLU**):"]},{"cell_type":"code","execution_count":16,"metadata":{"collapsed":true,"id":"sgm8bXjKj6ec","executionInfo":{"status":"ok","timestamp":1743373718842,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class ReLU(Module):\n","    def __init__(self):\n","         super(ReLU, self).__init__()\n","\n","    def updateOutput(self, input):\n","        self.output = np.maximum(input, 0)\n","        return self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        self.gradInput = np.multiply(gradOutput , input > 0)\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"ReLU\""]},{"cell_type":"markdown","metadata":{"id":"yB0UHGagj6ec"},"source":["## 10. (0.1) Leaky ReLU\n","Implement [**Leaky Rectified Linear Unit**](http://en.wikipedia.org/wiki%2FRectifier_%28neural_networks%29%23Leaky_ReLUs). Expriment with slope."]},{"cell_type":"code","execution_count":17,"metadata":{"id":"agwfkwO0j6ec","executionInfo":{"status":"ok","timestamp":1743373718859,"user_tz":-180,"elapsed":16,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class LeakyReLU(Module):\n","    def __init__(self, slope = 0.03):\n","        super(LeakyReLU, self).__init__()\n","\n","        self.slope = slope\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        self.output = np.where(input > 0, input, self.slope * input)\n","        return  self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        self.gradInput = gradOutput * np.where(input > 0, 1.0, self.slope)\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"LeakyReLU\""]},{"cell_type":"markdown","metadata":{"id":"t-STyecvj6ec"},"source":["## 11. (0.1) ELU\n","Implement [**Exponential Linear Units**](http://arxiv.org/abs/1511.07289) activations."]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":true,"id":"jJSzEu1mj6ec","executionInfo":{"status":"ok","timestamp":1743373718868,"user_tz":-180,"elapsed":8,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class ELU(Module):\n","    def __init__(self, alpha = 1.0):\n","        super(ELU, self).__init__()\n","\n","        self.alpha = alpha\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        self.output = np.where(input > 0, input, self.alpha * (np.exp(input) - 1))\n","        return  self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        self.gradInput = gradOutput * np.where(input > 0, 1, self.alpha * np.exp(input))\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"ELU\""]},{"cell_type":"markdown","metadata":{"id":"Gn3C7KTqj6ec"},"source":["## 12. (0.1) SoftPlus\n","Implement [**SoftPlus**](https://en.wikipedia.org/wiki%2FRectifier_%28neural_networks%29) activations. Look, how they look a lot like ReLU."]},{"cell_type":"code","execution_count":19,"metadata":{"collapsed":true,"id":"xcDPMssrj6ec","executionInfo":{"status":"ok","timestamp":1743373718890,"user_tz":-180,"elapsed":23,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class SoftPlus(Module):\n","    def __init__(self):\n","        super(SoftPlus, self).__init__()\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        max_input = np.maximum(input, 0)\n","        exp_term = np.exp(-np.abs(input))\n","        self.output = max_input + np.log1p(exp_term)\n","        return  self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        sigmoid = np.zeros_like(input)\n","        mask = (input >= 0)\n","\n","        sigmoid[mask] = 1.0 / (1.0 + np.exp(-input[mask]))\n","\n","        sigmoid[~mask] = np.exp(input[~mask]) / (1.0 + np.exp(input[~mask]))\n","        self.gradInput = gradOutput * sigmoid\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"SoftPlus\""]},{"cell_type":"markdown","source":["## 13. (0.2) Gelu\n","Implement [**Gelu**](https://pytorch.org/docs/stable/generated/torch.nn.GELU.html) activations."],"metadata":{"id":"kw3PeZjOuo0e"}},{"cell_type":"code","source":["class Gelu(Module):\n","    def __init__(self):\n","        super(Gelu, self).__init__()\n","\n","    def scalar_erf(self, x, n=1000):\n","      if x == 0:\n","        return 0.0\n","\n","      sign = 1 if x > 0 else -1\n","      x = abs(x)\n","\n","      t = np.linspace(0, x, n + 1)\n","      f = np.exp(-t**2)\n","      h = x / n\n","\n","      integral = h/3 * (f[0] + 4*np.sum(f[1:-1:2]) + 2*np.sum(f[2:-2:2]) + f[-1])\n","      return sign * 2/np.sqrt(np.pi) * integral\n","\n","\n","    def erf(self, arr, n=1000):\n","      erf_vectorized = np.vectorize(self.scalar_erf, excluded=['n'])\n","      return erf_vectorized(arr, n=n)\n","\n","    def updateOutput(self, input):\n","        # Your code goes here. ################################################\n","        self.output = input * 0.5 * (1 + self.erf(input / np.sqrt(2)))\n","        return  self.output\n","\n","    def updateGradInput(self, input, gradOutput):\n","        # Your code goes here. ################################################\n","        phi = (1.0 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * (input ** 2))\n","        cdf = 0.5 * (1 + self.erf(input / np.sqrt(2)))\n","        der = cdf + input * phi\n","        self.gradInput = gradOutput * der\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"Gelu\""],"metadata":{"id":"SdieE0Dtuo8j","executionInfo":{"status":"ok","timestamp":1743373718893,"user_tz":-180,"elapsed":1,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"55p7UvPAj6ec"},"source":["# Criterions"]},{"cell_type":"markdown","metadata":{"id":"5NFaxZaqj6ec"},"source":["Criterions are used to score the models answers."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"XGu45A8qj6ec","executionInfo":{"status":"ok","timestamp":1743373718927,"user_tz":-180,"elapsed":15,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class Criterion(object):\n","    def __init__ (self):\n","        self.output = None\n","        self.gradInput = None\n","\n","    def forward(self, input, target):\n","        \"\"\"\n","            Given an input and a target, compute the loss function\n","            associated to the criterion and return the result.\n","\n","            For consistency this function should not be overrided,\n","            all the code goes in `updateOutput`.\n","        \"\"\"\n","        return self.updateOutput(input, target)\n","\n","    def backward(self, input, target):\n","        \"\"\"\n","            Given an input and a target, compute the gradients of the loss function\n","            associated to the criterion and return the result.\n","\n","            For consistency this function should not be overrided,\n","            all the code goes in `updateGradInput`.\n","        \"\"\"\n","        return self.updateGradInput(input, target)\n","\n","    def updateOutput(self, input, target):\n","        \"\"\"\n","        Function to override.\n","        \"\"\"\n","        return self.output\n","\n","    def updateGradInput(self, input, target):\n","        \"\"\"\n","        Function to override.\n","        \"\"\"\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        \"\"\"\n","        Pretty printing. Should be overrided in every module if you want\n","        to have readable description.\n","        \"\"\"\n","        return \"Criterion\""]},{"cell_type":"markdown","metadata":{"id":"WuU26xkpj6ec"},"source":["The **MSECriterion**, which is basic L2 norm usually used for regression, is implemented here for you.\n","- input:   **`batch_size x n_feats`**\n","- target: **`batch_size x n_feats`**\n","- output: **scalar**"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"-i3VNuHhj6ec","executionInfo":{"status":"ok","timestamp":1743373718929,"user_tz":-180,"elapsed":1,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class MSECriterion(Criterion):\n","    def __init__(self):\n","        super(MSECriterion, self).__init__()\n","\n","    def updateOutput(self, input, target):\n","        self.output = np.sum(np.power(input - target, 2)) / input.shape[0]\n","        return self.output\n","\n","    def updateGradInput(self, input, target):\n","        self.gradInput  = (input - target) * 2 / input.shape[0]\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"MSECriterion\""]},{"cell_type":"markdown","metadata":{"id":"x8LKLWNVj6ec"},"source":["## 14. (0.2) Negative LogLikelihood criterion (numerically unstable)\n","You task is to implement the **ClassNLLCriterion**. It should implement [multiclass log loss](http://scikit-learn.org/stable/modules/model_evaluation.html#log-loss). Nevertheless there is a sum over `y` (target) in that formula,\n","remember that targets are one-hot encoded. This fact simplifies the computations a lot. Note, that criterions are the only places, where you divide by batch size. Also there is a small hack with adding small number to probabilities to avoid computing log(0).\n","- input:   **`batch_size x n_feats`** - probabilities\n","- target: **`batch_size x n_feats`** - one-hot representation of ground truth\n","- output: **scalar**\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"die7KvW6j6ec","executionInfo":{"status":"ok","timestamp":1743373718936,"user_tz":-180,"elapsed":5,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class ClassNLLCriterionUnstable(Criterion):\n","    EPS = 1e-15\n","    def __init__(self):\n","        a = super(ClassNLLCriterionUnstable, self)\n","        super(ClassNLLCriterionUnstable, self).__init__()\n","\n","    def updateOutput(self, input, target):\n","\n","        # Use this trick to avoid numerical errors\n","        input_clamp = np.clip(input, self.EPS, 1 - self.EPS)\n","\n","        # Your code goes here. ################################################\n","        selected_probs = np.sum(input_clamp * target, axis=1)\n","        self.output = -np.sum(np.log(selected_probs)) / input.shape[0]\n","        return self.output\n","\n","    def updateGradInput(self, input, target):\n","\n","        # Use this trick to avoid numerical errors\n","        input_clamp = np.clip(input, self.EPS, 1 - self.EPS)\n","\n","        # Your code goes here. ################################################\n","        self.gradInput = (-target / input_clamp) / input.shape[0]\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"ClassNLLCriterionUnstable\""]},{"cell_type":"markdown","metadata":{"id":"uHr_JbU5j6ec"},"source":["## 15. (0.3) Negative LogLikelihood criterion (numerically stable)\n","- input:   **`batch_size x n_feats`** - log probabilities\n","- target: **`batch_size x n_feats`** - one-hot representation of ground truth\n","- output: **scalar**\n","\n","Task is similar to the previous one, but now the criterion input is the output of log-softmax layer. This decomposition allows us to avoid problems with computation of forward and backward of log()."]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true,"id":"v7N8bVP9j6ec","executionInfo":{"status":"ok","timestamp":1743373718968,"user_tz":-180,"elapsed":30,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":["class ClassNLLCriterion(Criterion):\n","    def __init__(self):\n","        a = super(ClassNLLCriterion, self)\n","        super(ClassNLLCriterion, self).__init__()\n","\n","    def updateOutput(self, input, target):\n","        # Your code goes here. ################################################\n","        self.output = - (input * target).sum() / input.shape[0]\n","        return self.output\n","\n","    def updateGradInput(self, input, target):\n","        # Your code goes here. ################################################\n","        self.gradInput = - target / input.shape[0]\n","        return self.gradInput\n","\n","    def __repr__(self):\n","        return \"ClassNLLCriterion\""]},{"cell_type":"code","execution_count":24,"metadata":{"collapsed":true,"id":"E-ZnhKxaj6ed","executionInfo":{"status":"ok","timestamp":1743373718970,"user_tz":-180,"elapsed":6,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"outputs":[],"source":[]},{"cell_type":"markdown","source":["1-я часть задания: реализация слоев, лосей и функций активации - 5 баллов. \\\\\n","2-я часть задания: реализация моделей на своих классах. Что должно быть:\n","  1. Выберите оптимизатор и реализуйте его, чтоб он работал с вами классами. - 1 балл.\n","  2. Модель для задачи мультирегрессии на выбраных вами данных. Использовать FCNN, dropout, batchnorm, MSE. Пробуйте различные фукнции активации. Для первой модели попробуйте большую, среднюю и маленькую модель. - 1 балл.\n","  3. Модель для задачи мультиклассификации на MNIST. Использовать свёртки, макспулы, флэттэны, софтмаксы - 1 балла.\n","  4. Автоэнкодер для выбранных вами данных. Должен быть на свёртках и полносвязных слоях, дропаутах, батчнормах и тд. - 2 балла. \\\\\n","\n","Дополнительно в оценке каждой модели будет учитываться:\n","1. Наличие правильно выбранной метрики и лосс функции.\n","2. Отрисовка графиков лосей и метрик на трейне-валидации. Проверка качества модели на тесте.\n","3. Наличие шедулера для lr.\n","4. Наличие вормапа.\n","5. Наличие механизма ранней остановки и сохранение лучшей модели.\n","6. Свитч лося (метрики) и оптимайзера."],"metadata":{"id":"TC2Bf1PP2Ios"}},{"cell_type":"markdown","source":["# Пункт 1."],"metadata":{"id":"lFA0tZ5Z3Sb-"}},{"cell_type":"code","source":["class Adam:\n","    def __init__(self, params, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n","        self.params = list(params[\"params\"])  # Параметры модели (например, веса и смещения)\n","        self.grads = list(params[\"grads\"])\n","        self.lr = lr               # Скорость обучения\n","        self.beta1 = beta1         # Коэффициент для первого момента\n","        self.beta2 = beta2         # Коэффициент для второго момента\n","        self.epsilon = epsilon     # Малое число для стабильности\n","\n","        # Инициализация моментов\n","        self.m = [np.zeros_like(p) for p in self.params]\n","        self.v = [np.zeros_like(p) for p in self.params]\n","        self.t = 0                 # Счетчик шагов\n","\n","    def step(self):\n","        self.t += 1\n","        for i, (param, grad) in enumerate(zip(self.params, self.grads)):\n","            # Обновление моментов\n","            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n","            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * grad**2\n","\n","            # Коррекция смещения\n","            m_hat = self.m[i] / (1 - self.beta1**self.t)\n","            v_hat = self.v[i] / (1 - self.beta2**self.t)\n","\n","            # Обновление параметра\n","            param -= self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)\n","\n","    # def get_gradients(self):\n","    #   return [param.grad for param in self.params]\n","\n","    def zero_grad(self, params):\n","        # Для совместимости с PyTorch-подобным API (в этой реализации не используется)\n","        for param in self.params:\n","            param.grad.fill(0)\n","        pass"],"metadata":{"id":"Aq0X5QV55ZH4","executionInfo":{"status":"ok","timestamp":1743373718972,"user_tz":-180,"elapsed":6,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["# Пункт 2."],"metadata":{"id":"r2Xl0MoF496B"}},{"cell_type":"code","source":["# Параметры датасета\n","n_samples = 10000   # Количество образцов\n","n_features = 5     # Количество признаков\n","n_outputs = 3      # Количество целевых переменных\n","noise_scale = 0.2  # Уровень шума\n","\n","# Генерация признаков (X)\n","np.random.seed(42)\n","X = np.random.randn(n_samples, n_features)\n","\n","# Генерация истинных коэффициентов (весов) для каждого выхода\n","true_weights = np.random.randn(n_features, n_outputs) * 2  # Матрица [n_features x n_outputs]\n","true_bias = np.random.randn(n_outputs)                     # Вектор смещений [n_outputs]\n","\n","# Генерация целевых переменных (y) с шумом\n","y_true = X @ true_weights + true_bias  # Линейная комбинация\n","y = y_true + np.random.randn(n_samples, n_outputs) * noise_scale  # Шум для каждого выхода\n","\n","\n","\n","# Проверка размерностей\n","print(\"X shape:\", X.shape)  # (1000, 5)\n","print(\"y shape:\", y.shape)  # (1000, 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAJjiFxla5tx","executionInfo":{"status":"ok","timestamp":1743373719006,"user_tz":-180,"elapsed":39,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}},"outputId":"310ea292-3a48-42d8-84be-9102250a37bb"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["X shape: (10000, 5)\n","y shape: (10000, 3)\n"]}]},{"cell_type":"code","source":["def train_val_test_split(X, y, val_size=0.2, test_size=0.2, random_state=None):\n","    \"\"\"\n","    Параметры:\n","    - X: Массив признаков (n_samples, n_features).\n","    - y: Массив целевых значений (n_samples,).\n","    - test_size: Доля тестовой выборки (по умолчанию 0.2).\n","    - random_state: Seed для воспроизводимости.\n","    \"\"\"\n","    if random_state is not None:\n","        np.random.seed(random_state)\n","\n","    n_samples = X.shape[0]\n","    indices = np.arange(n_samples)\n","    np.random.shuffle(indices)  # Перемешивание индексов\n","\n","    test_samples = int(n_samples * test_size)\n","    val_samples = int(n_samples * val_size)\n","    train_samples = n_samples - test_samples - val_samples\n","\n","    X_train = X[indices[:train_samples]]\n","    X_val = X[indices[train_samples : train_samples + val_samples]]\n","    X_test = X[indices[train_samples + val_samples :]]\n","\n","    y_train = y[indices[:train_samples]]\n","    y_val = y[indices[train_samples : train_samples + val_samples]]\n","    y_test = y[indices[train_samples + val_samples :]]\n","\n","    return X_train, X_test, X_val, y_val, y_train, y_test"],"metadata":{"id":"DegJFtcXMDuz","executionInfo":{"status":"ok","timestamp":1743373719039,"user_tz":-180,"elapsed":4,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, X_val, y_val, y_train, y_test = train_val_test_split(X, y, 0.2, 0.2, random_state=30)"],"metadata":{"id":"oUgfIoW5N7rF","executionInfo":{"status":"ok","timestamp":1743373719041,"user_tz":-180,"elapsed":4,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Linear(5, 20))\n","model.add(Linear(20, 64))\n","model.add(BatchNormalization(64))\n","model.add(ReLU())\n","model.add(Dropout(0.3))\n","model.add(Linear(64, 20))\n","model.add(BatchNormalization(20))\n","model.add(ReLU())\n","model.add(Dropout(0.2))\n","model.add(Linear(20, 3))"],"metadata":{"id":"RxjCY18aBa74","executionInfo":{"status":"ok","timestamp":1743373719073,"user_tz":-180,"elapsed":31,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["loss = MSECriterion()\n","\n","parameters = []\n","grads = []\n","for module in model.modules:\n","    if isinstance(module, Linear):\n","        parameters.extend(module.getParameters())  # W и b как отдельные параметры\n","        grads.extend(module.getGradParameters())\n","\n","all_parameters = {\"params\": parameters, \"grads\": grads}\n","\n","optimizer = Adam(all_parameters, lr=0.001)"],"metadata":{"id":"nLoF-KyGBw-r","executionInfo":{"status":"ok","timestamp":1743373719076,"user_tz":-180,"elapsed":4,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["def train_model(model, loss_function, optimizer, X_train, y_train, X_val, y_val, epochs=5, batch_size=32):\n","\n","    train_losses, val_losses = [], []\n","    train_mse, val_mse = [], []\n","\n","    # training\n","    for epoch in range(epochs):\n","      running_loss, running_mse = 0, 0\n","\n","      for i in range(0, X_train.shape[0], batch_size):\n","          X_batch = X_train[i:i+batch_size]\n","          y_batch = y_train[i:i+batch_size]\n","\n","          # Прямое распространение\n","          output = model.updateOutput(X_batch)\n","          loss_score = loss_function.updateOutput(output, y_batch)\n","          running_loss += loss_score * batch_size\n","          running_mse += loss_function.updateOutput(output, y_batch) #?\n","\n","          # Обратное распространение\n","          gradOutput = loss_function.updateGradInput(output, y_batch)\n","          model.zeroGradParameters()\n","          model.backward(X_batch, gradOutput)\n","\n","          # Обновление параметров через Adam\n","          optimizer.step()\n","\n","      train_losses.append(running_loss/X_train.shape[0])\n","      train_mse.append(running_mse)\n","\n","      running_val_loss = 0\n","      running_val_mse = 0\n","      # validation\n","      for i in range(0, len(X_val), batch_size):\n","          output = model.updateOutput(X_val[i:i+batch_size])\n","          running_val_loss += loss_function.updateOutput(output, y_val[i:i+batch_size]) * batch_size\n","          running_val_mse += loss_function.updateOutput(output, y_val[i:i+batch_size])\n","\n","      val_losses.append(running_val_loss/X_val.shape[0])\n","      val_mse.append(running_val_mse)\n","\n","    return (train_mse, val_mse), (train_losses, val_losses)"],"metadata":{"id":"FOz60FASJZxo","executionInfo":{"status":"ok","timestamp":1743373719081,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["history = train_model(model, loss, optimizer, X_train, y_train, X_val, y_val, 10, 16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mU7xZnxXkvZ7","executionInfo":{"status":"ok","timestamp":1743373722979,"user_tz":-180,"elapsed":3896,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}},"outputId":"ff77a43d-a541-4df3-98b5-c71b95edf3c5"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-98778572745a>:25: RuntimeWarning: overflow encountered in multiply\n","  self.moving_mean = self.alpha * self.moving_mean + (1 - self.alpha) * self.batch_mean\n","<ipython-input-10-98778572745a>:26: RuntimeWarning: overflow encountered in multiply\n","  self.moving_variance = self.alpha * (self.moving_variance + self.EPS) + (1 - self.alpha) * self.batch_var\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(12,4))\n","\n","# График точности\n","plt.subplot(1,2,1)\n","plt.plot(history[0][0], label='Train MSE')\n","plt.plot(history[0][1], label='Validation MSE')\n","plt.title('Model Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.grid(True)\n","\n","# График потерь\n","plt.subplot(1,2,2)\n","plt.plot(history[1][0], label='Training Loss')\n","plt.plot(history[1][1], label='Validation Loss')\n","plt.title('Model Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410},"id":"CuEyGJVLv-QT","executionInfo":{"status":"ok","timestamp":1743373723805,"user_tz":-180,"elapsed":823,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}},"outputId":"781c2559-8c9d-48ae-fb22-a371361a35bf"},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x400 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Оценка модели на тестовом наборе\n","def test_model(model, loss_function, X_test, y_test, batch_size=32):\n","  test_loss = 0.0\n","  test_mse = 0.0\n","\n","  for i in range(0, len(X_test), batch_size):\n","        X_batch = X_test[i:i+batch_size]\n","        y_batch = y_test[i:i+batch_size]\n","\n","        output = model.updateOutput(X_batch)\n","        batch_mse = loss_function.updateOutput(output, y_batch)\n","        test_loss += batch_mse * len(X_batch)\n","        test_mse += batch_mse\n","\n","\n","  print(f'Test Loss: {test_loss / X_test.shape[0]:.4f}')\n","  print(f'Test MSE: {test_mse:.4f}')"],"metadata":{"id":"SNIRj18X1tYS","executionInfo":{"status":"ok","timestamp":1743373723814,"user_tz":-180,"elapsed":6,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["test_model(model, loss, X_test, y_test, 16)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlvzRQbo21zm","executionInfo":{"status":"ok","timestamp":1743373723835,"user_tz":-180,"elapsed":17,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}},"outputId":"e89ab800-e3b6-431c-9360-7de619a77979"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Loss: 6.6649\n","Test MSE: 833.1126\n"]}]},{"cell_type":"markdown","source":["# Пункт 3"],"metadata":{"id":"TPq6l2MR405P"}},{"cell_type":"code","source":[],"metadata":{"id":"WGrhj6Mk43NO","executionInfo":{"status":"ok","timestamp":1743373723841,"user_tz":-180,"elapsed":4,"user":{"displayName":"Dmitry Sokolov","userId":"07962866469303797928"}}},"execution_count":35,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"collapsed_sections":["ZuwvBkuNj6ea","tNOnHXZJj6eb","Cy3DJjynj6eb"],"gpuType":"T4"}},"nbformat":4,"nbformat_minor":0}